{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3327e4dd-f411-4581-94e0-1f66ac564a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assignment 06 - Artificial Neural Networks\n",
    "# CS 131 - Artificial Intelligence\n",
    "# Darcy Corson (dcorso01)\n",
    "# May 2024\n",
    "#\n",
    "# This Python script implements a neural network from scratch to classify Iris species based on their flower measurements.\n",
    "# It leverages numpy for numerical operations, pandas for data handling, and scikit-learn for data preprocessing and splitting.\n",
    "# The script features functions for both forward and backward propagation, loss calculations, and the training process includes\n",
    "# early stopping for optimization. Users can interactively input flower measurements to receive predictions on Iris species."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1afd6d-33d9-4e72-bab2-1724774d37a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea860e41-96e1-464e-84f5-2cdded1b505d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assignment 06 - Artificial Neural Networks\n",
    "# CS 131 - Artificial Intelligence\n",
    "# Darcy Corson (dcorso01)\n",
    "# May 2024\n",
    "#\n",
    "# This Python script implements a neural network from scratch to classify Iris species based on their flower measurements. \n",
    "# It leverages numpy for numerical operations, pandas for data handling, and scikit-learn for data preprocessing and splitting. \n",
    "# The script features functions for both forward and backward propagation, loss calculations, and the training process includes \n",
    "# early stopping for optimization. Users can interactively input flower measurements to receive predictions on Iris species.\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "def mse_loss(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Purpose: calculates the mean squared error loss between the true labels and the predictions during training; helps in monitoring \n",
    "    the performance of the model during the training phase\n",
    "    Inputs:\n",
    "        y_true: the true labels\n",
    "        y_pred: the predicted outputs\n",
    "    Outputs: (float): computed MSE value\n",
    "    Effects: none\n",
    "    \"\"\"\n",
    "    return ((y_true - y_pred) ** 2).mean()\n",
    "\n",
    "def sigmoid(x):\n",
    "    \"\"\"\n",
    "    Purpose: the activation function for the hidden layer neurons, transforming the weighted inputs to a non-linear output\n",
    "    Inputs: x: input array or scalar \n",
    "    Outputs: result of applying the sigmoid function element-wise\n",
    "    Effects: none\n",
    "    \"\"\"\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    \"\"\"\n",
    "    Purpose: calculates the gradient of the sigmoid function for updating the weights\n",
    "    Inputs: x: input array or scalar\n",
    "    Outputs: derivative of the sigmoid function applied element-wise\n",
    "    Effects: none\n",
    "    \"\"\"\n",
    "    return x * (1 - x)\n",
    "\n",
    "def softmax(x):\n",
    "    \"\"\"\n",
    "    Purpose: converts logits to probabilities that sum to one\n",
    "    Inputs: x: input array of logits\n",
    "    Outputs: probabilities from applying softmax\n",
    "    Effects: none\n",
    "    \"\"\"\n",
    "    exps = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
    "    return exps / np.sum(exps, axis=1, keepdims=True)\n",
    "\n",
    "def categorical_cross_entropy_loss(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Purpose: computes the loss between the one-hot encoded true labels and the predicted probabilities from the softmax function\n",
    "    Inputs:\n",
    "        y_true: one-hot encoded true labels\n",
    "        y_pred: predicted probabilities\n",
    "    Outputs: calculated loss value\n",
    "    Effects: none\n",
    "    \"\"\"\n",
    "    y_pred = np.clip(y_pred, 1e-15, 1 - 1e-15)\n",
    "    loss = -np.sum(y_true * np.log(y_pred)) / len(y_true)\n",
    "    return loss\n",
    "\n",
    "class NeuralNetwork:\n",
    "    def __init__(self, input_nodes, hidden_nodes, output_nodes):\n",
    "        \"\"\"\n",
    "        Purpose: initialize the neural network \n",
    "        Inputs:\n",
    "            input_nodes: Number of input nodes.\n",
    "            hidden_nodes: Number of hidden nodes.\n",
    "            output_nodes: Number of output nodes.\n",
    "        Outputs: none\n",
    "        Effects: sets initial weights and biases, configures the layer sizes, sets learning rate\n",
    "        \"\"\"\n",
    "        self.input_nodes = input_nodes\n",
    "        self.hidden_nodes = hidden_nodes\n",
    "        self.output_nodes = output_nodes\n",
    "\n",
    "        # Initialize weights \n",
    "        self.weights_input_hidden = np.random.randn(self.input_nodes, self.hidden_nodes) * np.sqrt(2. / self.input_nodes)\n",
    "        self.weights_hidden_output = np.random.randn(self.hidden_nodes, self.output_nodes) * np.sqrt(2. / self.hidden_nodes)\n",
    "\n",
    "        # Initialize biases \n",
    "        self.bias_hidden = np.zeros((1, self.hidden_nodes))\n",
    "        self.bias_output = np.zeros((1, self.output_nodes))\n",
    "\n",
    "        self.lr = 0.01  # Learning rate\n",
    "\n",
    "    def feedforward(self, X):\n",
    "        \"\"\"\n",
    "        Purpose: performs a forward pass through the network\n",
    "        Inputs:\n",
    "            X: input features\n",
    "        Outputs:\n",
    "            softmax output of the network\n",
    "        Effects:\n",
    "            sets hidden and output layer activations as class attributes\n",
    "        \"\"\"\n",
    "        self.hidden_layer_input = np.dot(X, self.weights_input_hidden) + self.bias_hidden\n",
    "        self.hidden_layer_output = sigmoid(self.hidden_layer_input)\n",
    "        self.output_layer_input = np.dot(self.hidden_layer_output, self.weights_hidden_output) + self.bias_output\n",
    "        self.output_layer_output = softmax(self.output_layer_input)\n",
    "        return self.output_layer_output\n",
    "\n",
    "\n",
    "    def backpropagation(self, inputs, expected_output, output):\n",
    "        \"\"\"\n",
    "        Purpose: adjusts the weights and biases based on the error gradient\n",
    "        Inputs:\n",
    "            inputs: Input data for one training sample.\n",
    "            expected_output: Expected output (target) for the corresponding input.\n",
    "            output: Actual output produced by the feedforward pass before backpropagation.\n",
    "        Outputs:\n",
    "        Effects: updates the weights and biases between/for input-hidden and hidden-output layers\n",
    "        \"\"\"\n",
    "        # Error in output layer \n",
    "        error_output_layer = expected_output - output\n",
    "        \n",
    "        # Error in hidden layer\n",
    "        error_hidden_layer = error_output_layer.dot(self.weights_hidden_output.T)\n",
    "        d_hidden_layer = error_hidden_layer * sigmoid_derivative(self.hidden_layer_output)\n",
    "        \n",
    "        # Update weights and biases\n",
    "        self.weights_hidden_output += self.hidden_layer_output.T.dot(error_output_layer) * self.lr\n",
    "        self.weights_input_hidden += inputs.T.dot(d_hidden_layer) * self.lr\n",
    "        self.bias_hidden += np.sum(d_hidden_layer, axis=0, keepdims=True) * self.lr\n",
    "        self.bias_output += np.sum(error_output_layer, axis=0, keepdims=True) * self.lr\n",
    "\n",
    "    def train(self, X_train, y_train, X_val, y_val, epochs, patience=100):\n",
    "        \"\"\"\n",
    "        Purpose: manages the iterative training process\n",
    "        Inputs:\n",
    "            X_train: training dataset inputs\n",
    "            y_train: training dataset targets\n",
    "            X_val: validation dataset inputs\n",
    "            y_val: validation dataset targets\n",
    "            epochs: total number of epochs to train\n",
    "            patience: number of epochs to wait for improvement in validation loss before early stopping\n",
    "        Outputs: none\n",
    "        Effects: trains the neural network by adjusting weights and biases\n",
    "        \"\"\"\n",
    "        best_val_loss = np.inf\n",
    "        patience_counter = 0  \n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            output_train = []\n",
    "            for inputs, labels in zip(X_train, y_train):\n",
    "                inputs = np.array([inputs])  \n",
    "                outputs = self.feedforward(inputs)\n",
    "                output_train.append(outputs)\n",
    "                self.backpropagation(inputs, labels, outputs)\n",
    "\n",
    "            # Calculate training MSE and accuracy\n",
    "            output_train = np.vstack(output_train)  # Stack output arrays\n",
    "            train_mse = mse_loss(y_train, output_train)\n",
    "            predicted_classes = np.argmax(output_train, axis=1)\n",
    "            true_classes = np.argmax(y_train, axis=1)\n",
    "            train_accuracy = np.mean(predicted_classes == true_classes) * 100\n",
    "            \n",
    "            # Calculate validation loss\n",
    "            val_outputs = self.feedforward(X_val)\n",
    "            val_loss = categorical_cross_entropy_loss(y_val, val_outputs)\n",
    "            print(f'Epoch {epoch+1}, Training MSE = {train_mse:.4f}, Training Accuracy: {train_accuracy:.2f}%, Validation Loss: {val_loss:.4f}')\n",
    "            \n",
    "            # Early stopping logic\n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                patience_counter = 0  \n",
    "            else:\n",
    "                patience_counter += 1  \n",
    "            \n",
    "            if patience_counter >= patience:\n",
    "                print(f'Stopping early after {epoch+1} epochs')\n",
    "                break\n",
    "\n",
    "def load_data(filepath):\n",
    "    \"\"\"\n",
    "    Purpose: loads and preprocesses the dataset\n",
    "    Inputs: filepath: path to the dataset file\n",
    "    Outputs: a tuple containing ormalized feature values and one-hot encoded target labels\n",
    "    Effects: normalizes feature columns and one-hot encodes the target labels\n",
    "    \"\"\"\n",
    "    dataset = pd.read_csv(filepath, header=None)\n",
    "    \n",
    "    # Normalize features\n",
    "    normalized_features = (dataset.iloc[:, :-1] - dataset.iloc[:, :-1].mean(axis=0)) / dataset.iloc[:, :-1].std(axis=0)\n",
    "    \n",
    "    # One-hot encode target labels\n",
    "    encoder = LabelEncoder()\n",
    "    targets = encoder.fit_transform(dataset.iloc[:, -1])\n",
    "    targets = np.eye(np.unique(targets).size)[targets]  \n",
    "    \n",
    "    return normalized_features.values, targets\n",
    "\n",
    "def predict(model, input_features):\n",
    "    \"\"\"\n",
    "    Purpose: makes predictions on new data inputs using the trained network\n",
    "    Inputs:\n",
    "        model: trained neural network model\n",
    "        input_features: features of the new data input for prediction\n",
    "    Outputs: returns the predicted class label for the input data\n",
    "    Effects: none\n",
    "    \"\"\"\n",
    "    output = model.feedforward(input_features)\n",
    "    class_labels = ['Iris-setosa', 'Iris-versicolor', 'Iris-virginica']\n",
    "    return class_labels[np.argmax(output)]\n",
    "\n",
    "def evaluate_accuracy(test_outputs, y_test):\n",
    "    \"\"\"\n",
    "    Purpose: assesses the performance of the network on test data\n",
    "    Inputs:\n",
    "        test_outputs: uutput predictions of the neural network for the test data\n",
    "        y_test: actual target labels for the test data\n",
    "    Outputs: the accuracy of the predictions\n",
    "    Effects: none\n",
    "    \"\"\"\n",
    "    \n",
    "    test_outputs = np.squeeze(test_outputs, axis=1)\n",
    "    encoder = LabelEncoder()\n",
    "    true_classes = encoder.fit_transform(np.argmax(y_test, axis=1))\n",
    "    predicted_classes = np.argmax(test_outputs, axis=1)\n",
    "    true_classes_encoded = np.eye(np.unique(predicted_classes).size)[true_classes]\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = np.mean(predicted_classes == np.argmax(true_classes_encoded, axis=1))\n",
    "    print(\"Test accuracy:\", accuracy)\n",
    "\n",
    "    return accuracy\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    filepath = '/Users/dcorson/Desktop/ANN - iris data.txt'\n",
    "    X, y = load_data(filepath)\n",
    "    X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.25, random_state=42)\n",
    "    \n",
    "    nn = NeuralNetwork(input_nodes=4, hidden_nodes=5, output_nodes=3)\n",
    "    nn.train(X_train, y_train, X_val, y_val, epochs=1000)\n",
    "    \n",
    "    test_outputs = np.array([nn.feedforward(np.array([x])) for x in X_test])\n",
    "    test_accuracy = evaluate_accuracy(test_outputs, y_test)\n",
    "    print(f'Test Accuracy: {test_accuracy:.2f}')\n",
    "\n",
    "    while True:\n",
    "        print(\"\\nEnter the sepal length, sepal width, petal length, and petal width of the Iris (or 'Q' to quit):\")\n",
    "        sl_input = input(\"Sepal length (cm): \")\n",
    "        if sl_input.lower() == 'q':\n",
    "            break\n",
    "\n",
    "        try:\n",
    "            sl = float(sl_input)\n",
    "            sw = float(input(\"Sepal width (cm): \"))\n",
    "            pl = float(input(\"Petal length (cm): \"))\n",
    "            pw = float(input(\"Petal width (cm): \"))\n",
    "        except ValueError:\n",
    "            print(\"Invalid input. Please enter numeric values.\")\n",
    "            continue\n",
    "\n",
    "        user_input = np.array([[sl, sw, pl, pw]])\n",
    "        dataset = pd.read_csv(filepath, header=None)  \n",
    "        mean = dataset.iloc[:, :-1].mean(axis=0)\n",
    "        std = dataset.iloc[:, :-1].std(axis=0)\n",
    "        normalized_user_input = (user_input - mean.values) / std.values\n",
    "\n",
    "        normalized_user_input = normalized_user_input.reshape(1, -1)\n",
    "\n",
    "        prediction = predict(nn, normalized_user_input)\n",
    "        print(f\"The predicted Iris class is: {prediction}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "083aec78-9d2c-416f-88e5-40255865d0a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11",
   "language": "python",
   "name": "python311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
